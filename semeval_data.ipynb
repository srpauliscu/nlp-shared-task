{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "b3W2ywtdABiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Format\n",
        "\n",
        "**Data:** `arguments-training/validation/testing.tsv`\n",
        "(5220 arguments)\n",
        "- Argument ID\n",
        "- Conclusion \n",
        "- Stance (e.g., in favor, against)\n",
        "- Premise (justification for conclusion)\n",
        "\n",
        "**Labels:** `labels-training/validation/testing.tsv` \n",
        "(20 binary value labels per argument)\n",
        "- Argument ID\n",
        "- Self-direction: thought\n",
        "- Self-direction: action\n",
        "- Stimulation\n",
        "- Hedonism\n",
        "- Achievement\n",
        "- Power: dominance\n",
        "- Power: resources\n",
        "- Face\n",
        "- Security: personal\n",
        "- Security: societal\n",
        "- Tradition\n",
        "- Conformity: rules\n",
        "- Conformity: interpersonal\n",
        "- Humility\n",
        "- Benevolence: caring\n",
        "- Benevolence: dependability\n",
        "- Universalism: concern\n",
        "- Universalism: nature\n",
        "- Universalism: tolerance\n",
        "- Universalism: objectivity\n",
        "\n",
        "**Access:** https://doi.org/10.5281/zenodo.6814563"
      ],
      "metadata": {
        "id": "X2Bgm5JhCPPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "4dEBasNDF6Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clear working environment\n",
        "%reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHAtlPPEIJpZ",
        "outputId": "8c7f0ff8-af57-44f7-dc81-a44f008ac3bd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JXuWLoltF_wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803b70fa-5406-4cb1-d16f-732a883ba02f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lORatXxJmjjR",
        "outputId": "277ba6df-a85d-40b1-acb8-e69722d8992c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from typing import Dict, List\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "7MiENnaFF5ra"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "IYMeIf-cEz4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training arguments\n",
        "train_args_df = pd.read_csv('/content/drive/MyDrive/csci5832_project/data/arguments-training.tsv', sep='\\t')\n",
        "# view structure\n",
        "train_args_df.info()"
      ],
      "metadata": {
        "id": "H9k2Hl9REzjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f00bcc-aa1f-488f-f3a8-1476c8f45230"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5220 entries, 0 to 5219\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Argument ID  5220 non-null   object\n",
            " 1   Conclusion   5220 non-null   object\n",
            " 2   Stance       5220 non-null   object\n",
            " 3   Premise      5220 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 163.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training labels\n",
        "train_labs_df = pd.read_csv('/content/drive/MyDrive/csci5832_project/data/labels-training.tsv', sep='\\t')\n",
        "# view structure\n",
        "train_labs_df.info()"
      ],
      "metadata": {
        "id": "YW-jlIILANgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c987ab-59c2-47af-fca3-9c394b200a56"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5220 entries, 0 to 5219\n",
            "Data columns (total 21 columns):\n",
            " #   Column                      Non-Null Count  Dtype \n",
            "---  ------                      --------------  ----- \n",
            " 0   Argument ID                 5220 non-null   object\n",
            " 1   Self-direction: thought     5220 non-null   int64 \n",
            " 2   Self-direction: action      5220 non-null   int64 \n",
            " 3   Stimulation                 5220 non-null   int64 \n",
            " 4   Hedonism                    5220 non-null   int64 \n",
            " 5   Achievement                 5220 non-null   int64 \n",
            " 6   Power: dominance            5220 non-null   int64 \n",
            " 7   Power: resources            5220 non-null   int64 \n",
            " 8   Face                        5220 non-null   int64 \n",
            " 9   Security: personal          5220 non-null   int64 \n",
            " 10  Security: societal          5220 non-null   int64 \n",
            " 11  Tradition                   5220 non-null   int64 \n",
            " 12  Conformity: rules           5220 non-null   int64 \n",
            " 13  Conformity: interpersonal   5220 non-null   int64 \n",
            " 14  Humility                    5220 non-null   int64 \n",
            " 15  Benevolence: caring         5220 non-null   int64 \n",
            " 16  Benevolence: dependability  5220 non-null   int64 \n",
            " 17  Universalism: concern       5220 non-null   int64 \n",
            " 18  Universalism: nature        5220 non-null   int64 \n",
            " 19  Universalism: tolerance     5220 non-null   int64 \n",
            " 20  Universalism: objectivity   5220 non-null   int64 \n",
            "dtypes: int64(20), object(1)\n",
            "memory usage: 856.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep Data"
      ],
      "metadata": {
        "id": "8Uvfel3EE17z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert multiple label columns to one label list column\n",
        "train_labs_df['labels'] = train_labs_df.loc[:, 'Self-direction: thought':'Universalism: objectivity'].values.tolist()"
      ],
      "metadata": {
        "id": "G6Ov0b5mmKtn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label distribution for full training data\n",
        "print('Self-direction: thought =', sum(train_labs_df['Self-direction: thought']))\n",
        "print('Self-direction: action =', sum(train_labs_df['Self-direction: action']))\n",
        "print('Stimulation =', sum(train_labs_df['Stimulation']))\n",
        "print('Hedonism =', sum(train_labs_df['Hedonism']))\n",
        "print('Achievement = ', sum(train_labs_df['Achievement']))\n",
        "print('Power: dominance =', sum(train_labs_df['Power: dominance']))\n",
        "print('Power: resources =', sum(train_labs_df['Power: resources']))\n",
        "print('Face =', sum(train_labs_df['Face']))\n",
        "print('Security: personal =', sum(train_labs_df['Security: personal']))\n",
        "print('Security: societal =', sum(train_labs_df['Security: societal']))\n",
        "print('Tradition =', sum(train_labs_df['Tradition']))\n",
        "print('Conformity: rules =', sum(train_labs_df['Conformity: rules']))\n",
        "print('Conformity: interpersonal =', sum(train_labs_df['Conformity: interpersonal']))\n",
        "print('Humility =', sum(train_labs_df['Humility']))\n",
        "print('Benevolence: caring =', sum(train_labs_df['Benevolence: caring']))\n",
        "print('Benevolence: dependability =', sum(train_labs_df['Benevolence: dependability']))\n",
        "print('Universalism: concern =', sum(train_labs_df['Universalism: concern']))\n",
        "print('Universalism: nature =', sum(train_labs_df['Universalism: nature']))\n",
        "print('Universalism: tolerance =', sum(train_labs_df['Universalism: tolerance']))\n",
        "print('Universalism: objectivity =', sum(train_labs_df['Universalism: objectivity']))\n",
        "\n",
        "print('\\nTotal number of samples = ', len(train_labs_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frLZrgKw26yv",
        "outputId": "1738146f-8645-40f5-e869-500ba522c507"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-direction: thought = 913\n",
            "Self-direction: action = 1332\n",
            "Stimulation = 312\n",
            "Hedonism = 202\n",
            "Achievement =  1400\n",
            "Power: dominance = 461\n",
            "Power: resources = 566\n",
            "Face = 374\n",
            "Security: personal = 1961\n",
            "Security: societal = 1627\n",
            "Tradition = 598\n",
            "Conformity: rules = 1222\n",
            "Conformity: interpersonal = 217\n",
            "Humility = 438\n",
            "Benevolence: caring = 1500\n",
            "Benevolence: dependability = 766\n",
            "Universalism: concern = 1992\n",
            "Universalism: nature = 358\n",
            "Universalism: tolerance = 709\n",
            "Universalism: objectivity = 937\n",
            "\n",
            "Total number of samples =  5220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine dfs to add label list to data dictionary\n",
        "train_merged_df = pd.merge(train_args_df, train_labs_df, on='Argument ID')\n",
        "train_merged_df = train_merged_df.drop(columns=['Self-direction: thought',\n",
        "                                                'Self-direction: action',\n",
        "                                                'Stimulation',\n",
        "                                                'Hedonism',\n",
        "                                                'Achievement',\n",
        "                                                'Power: dominance',\n",
        "                                                'Power: resources',\n",
        "                                                'Face',\n",
        "                                                'Security: personal',\n",
        "                                                'Security: societal',\n",
        "                                                'Tradition',\n",
        "                                                'Conformity: rules',\n",
        "                                                'Conformity: interpersonal',\n",
        "                                                'Humility',\n",
        "                                                'Benevolence: caring',\n",
        "                                                'Benevolence: dependability',\n",
        "                                                'Universalism: concern',\n",
        "                                                'Universalism: nature',\n",
        "                                                'Universalism: tolerance',\n",
        "                                                'Universalism: objectivity'])"
      ],
      "metadata": {
        "id": "349ZmqVtANb_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view structure\n",
        "train_merged_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Gi6B4Tp-1S",
        "outputId": "ebe99271-1d52-4f30-8699-562c82b237a5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5220 entries, 0 to 5219\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Argument ID  5220 non-null   object\n",
            " 1   Conclusion   5220 non-null   object\n",
            " 2   Stance       5220 non-null   object\n",
            " 3   Premise      5220 non-null   object\n",
            " 4   labels       5220 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 244.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split"
      ],
      "metadata": {
        "id": "qOnSRjeqzvf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split train data into 80/20 train/val\n",
        "train_data, val_data = train_test_split(train_merged_df, test_size=0.2, random_state=4)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "Y4wusIBmzuzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "853615af-8193-4675-9d59-96af53f13823"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Argument ID                                     Conclusion       Stance  \\\n",
              "4531      A07017          Homeopathy brings more harm than good      against   \n",
              "4475      A24284                   We should abandon television      against   \n",
              "1031      A18184                  We should abolish safe spaces      against   \n",
              "1471      A19216  Assisted suicide should be a criminal offence  in favor of   \n",
              "4411      A22162                        We should adopt atheism      against   \n",
              "\n",
              "                                                Premise  \\\n",
              "4531  homeopathy uses natural remedies that have lit...   \n",
              "4475  Television is the gateway for many to news and...   \n",
              "1031  safe spaces are important for those who do not...   \n",
              "1471         assisted suicide is heartless and inhumane   \n",
              "4411  anyone is entitled to believe in whatever they...   \n",
              "\n",
              "                                                 labels  \n",
              "4531  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
              "4475  [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1031  [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
              "1471  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...  \n",
              "4411  [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00bcac5d-30d4-4362-aa27-ff9a49f2a16a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Argument ID</th>\n",
              "      <th>Conclusion</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4531</th>\n",
              "      <td>A07017</td>\n",
              "      <td>Homeopathy brings more harm than good</td>\n",
              "      <td>against</td>\n",
              "      <td>homeopathy uses natural remedies that have lit...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4475</th>\n",
              "      <td>A24284</td>\n",
              "      <td>We should abandon television</td>\n",
              "      <td>against</td>\n",
              "      <td>Television is the gateway for many to news and...</td>\n",
              "      <td>[1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1031</th>\n",
              "      <td>A18184</td>\n",
              "      <td>We should abolish safe spaces</td>\n",
              "      <td>against</td>\n",
              "      <td>safe spaces are important for those who do not...</td>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>A19216</td>\n",
              "      <td>Assisted suicide should be a criminal offence</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>assisted suicide is heartless and inhumane</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>A22162</td>\n",
              "      <td>We should adopt atheism</td>\n",
              "      <td>against</td>\n",
              "      <td>anyone is entitled to believe in whatever they...</td>\n",
              "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00bcac5d-30d4-4362-aa27-ff9a49f2a16a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00bcac5d-30d4-4362-aa27-ff9a49f2a16a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00bcac5d-30d4-4362-aa27-ff9a49f2a16a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert each row to a dictionary -> List[Dict]\n",
        "train_data = train_data.to_dict(orient='records')\n",
        "val_data = val_data.to_dict(orient='records')\n",
        "full_data = train_merged_df.to_dict(orient='records')\n",
        "# print examples\n",
        "print('training example:\\n', train_data[0])\n",
        "print('validation example:\\n', val_data[0])\n",
        "print('full example:\\n', full_data[0])"
      ],
      "metadata": {
        "id": "lvUcmQ5Ijops",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57594c5e-4186-4e46-a676-50a292b48aeb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training example:\n",
            " {'Argument ID': 'A07017', 'Conclusion': 'Homeopathy brings more harm than good', 'Stance': 'against', 'Premise': 'homeopathy uses natural remedies that have little to no side affects on the body.', 'labels': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]}\n",
            "validation example:\n",
            " {'Argument ID': 'A18174', 'Conclusion': 'The vow of celibacy should be abandoned', 'Stance': 'against', 'Premise': \"the vow of celibacy should be promoted as it brings the sense of self control and purity to a person's soul.\", 'labels': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]}\n",
            "full example:\n",
            " {'Argument ID': 'A01001', 'Conclusion': 'Entrapment should be legalized', 'Stance': 'in favor of', 'Premise': \"if entrapment can serve to more easily capture wanted criminals, then why shouldn't it be legal?\", 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "eIFcUB2EcI_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to load samples from HuggingFace dataset to be batched and encoded\n",
        "\n",
        "class BatchTokenizer:\n",
        "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
        "    \"\"\"HuggingFace docs: https://huggingface.co/transformers/v3.0.2/preprocessing.html\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes the tokenizer\n",
        "\n",
        "        Args:\n",
        "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
        "        \"\"\"\n",
        "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\")\n",
        "    \n",
        "    # HuggingFace tokenizer will join data with sentence separator token\n",
        "    # and match batches of tokenized and encoded sentences\n",
        "    def get_sep_token(self,):\n",
        "        return self.hf_tokenizer.sep_token\n",
        "\n",
        "    # call method can only take a pair of inputs, but we have three\n",
        "    # conclusion batch, stance batch, and premise batch\n",
        "    # so we create a hack\n",
        "    #def __call__(self, con_batch: List[str], stan_batch: List[str], prem_batch: List[str]) -> List[List[str]]:\n",
        "\n",
        "    def __call__(self, con_stan_batch: List[str], prem_batch: List[str]) -> List[List[str]]:  \n",
        "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
        "\n",
        "        We return a dictionary of tensors per the huggingface model specification.\n",
        "\n",
        "        Args:\n",
        "            batch (List[str]): A List of sentence strings\n",
        "\n",
        "        Returns:\n",
        "            Dict: The dictionary of token specifications provided by HuggingFace\n",
        "        \"\"\"\n",
        "        # The HF tokenizer will PAD for us, and additionally combine \n",
        "        # the two sentences deimited by the [SEP] token.\n",
        "        enc = self.hf_tokenizer(\n",
        "            con_stan_batch,\n",
        "            prem_batch,\n",
        "            #stan_batch,\n",
        "            #prem_batch,\n",
        "            padding=True,\n",
        "            return_token_type_ids=False, # ignore with hack\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return enc"
      ],
      "metadata": {
        "id": "1qO3HAWVcOwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define tokenizer\n",
        "tokenizer = BatchTokenizer()"
      ],
      "metadata": {
        "id": "9suBPQW7tNRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of use case for batch tokenizer\n",
        "#token_ex = tokenizer(*[['this is the conclusion.', 'this is also a conclusion'], ['this is the stance.', 'this is also a stance'], ['this is the premise', 'this is also a premise']])\n",
        "#tokenizer.hf_tokenizer.batch_decode(token_ex['input_ids'])\n",
        "# HF tokenizer not working for three input sentence types"
      ],
      "metadata": {
        "id": "La66aNazszlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of use case for batch tokenizer without triplet hack (only two input types acceptable)\n",
        "token_ex = tokenizer(*[['this is the conclusion with more words', 'this is also a conclusion'], ['this is the premise', 'this is the second premise']])\n",
        "print(token_ex)\n",
        "tokenizer.hf_tokenizer.batch_decode(token_ex['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwTE69y4mPZ4",
        "outputId": "8fd3c10a-c0f2-465c-c2db-5fbf91110406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2023,  2003,  1996,  7091,  2007,  2062,  2616,   102,  2023,\n",
            "          2003,  1996, 18458,   102],\n",
            "        [  101,  2023,  2003,  2036,  1037,  7091,   102,  2023,  2003,  1996,\n",
            "          2117, 18458,   102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] this is the conclusion with more words [SEP] this is the premise [SEP]',\n",
              " '[CLS] this is also a conclusion [SEP] this is the second premise [SEP] [PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of use case for batch tokenizer with triplet hack\n",
        "token_ex2 = tokenizer(*[['this is the conclusion with more words [SEP] and a stance against', 'this is also a conclusion [SEP] with another stance that is in favor of'], ['this is the premise', 'this is the second premise']])\n",
        "print(token_ex2)\n",
        "tokenizer.hf_tokenizer.batch_decode(token_ex2['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSlzDkBzwtl3",
        "outputId": "bd82cfd6-a1db-4b5a-a1df-64a15210dcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2023,  2003,  1996,  7091,  2007,  2062,  2616,   102,  1998,\n",
            "          1037, 11032,  2114,   102,  2023,  2003,  1996, 18458,   102,     0,\n",
            "             0,     0],\n",
            "        [  101,  2023,  2003,  2036,  1037,  7091,   102,  2007,  2178, 11032,\n",
            "          2008,  2003,  1999,  5684,  1997,   102,  2023,  2003,  1996,  2117,\n",
            "         18458,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] this is the conclusion with more words [SEP] and a stance against [SEP] this is the premise [SEP] [PAD] [PAD] [PAD]',\n",
              " '[CLS] this is also a conclusion [SEP] with another stance that is in favor of [SEP] this is the second premise [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch"
      ],
      "metadata": {
        "id": "e_C6dXRcs4zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate triple-wise inputs\n",
        "\n",
        "def generate_triplewise_input(dataset: List[Dict]) -> (List[str], List[str], List[str], List[str], List[List[int]]):\n",
        "    \"\"\"\n",
        "    group all argument components and corresponding labels of the datapoints\n",
        "    a datapoint is now a dictionary of \n",
        "    argument id, conclusion, stance, premise, and label list\n",
        "    \"\"\"\n",
        "\n",
        "    # extract each observation from dictionary; save to list\n",
        "    d_vals = []\n",
        "    for i in range(len(dataset)):\n",
        "        d_vals.append(list(dataset[i].values()))\n",
        "\n",
        "    # store data items in lists by three categories by id\n",
        "    id_lst = []    \n",
        "    conclusion_lst = []\n",
        "    stance_lst = []\n",
        "    premise_lst = []\n",
        "\n",
        "    # store labels in list of lists of 20 labels\n",
        "    label_lst = []\n",
        "\n",
        "    # generate separate lists from each observation\n",
        "    for i in range(len(d_vals)):\n",
        "        id_lst.append(d_vals[i][0])\n",
        "        conclusion_lst.append(d_vals[i][1])\n",
        "        stance_lst.append(d_vals[i][2])\n",
        "        premise_lst.append(d_vals[i][3])\n",
        "        label_lst.append(d_vals[i][4])\n",
        "\n",
        "    # add [SEP] token before every stance in list\n",
        "    stance_lst = [' [SEP] ' + s for s in stance_lst]\n",
        "\n",
        "    return id_lst, conclusion_lst, stance_lst, premise_lst, label_lst"
      ],
      "metadata": {
        "id": "uoLv-VD2s7VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function to generate triple-wise inputs and labels for batching\n",
        "\n",
        "# training data\n",
        "train_ids, train_conclusions, train_stances, train_premises, train_labels = generate_triplewise_input(train_data)\n",
        "\n",
        "# validation data\n",
        "val_ids, val_conclusions, val_stances, val_premises, val_labels = generate_triplewise_input(val_data)\n",
        "\n",
        "# full data\n",
        "full_ids, full_conclusions, full_stances, full_premises, full_labels = generate_triplewise_input(full_data)"
      ],
      "metadata": {
        "id": "SiVoKuDw5nXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temporarily combine conclusions and stances separate with [SEP]\n",
        "# use hack to merge tokenized conclusion batch, stance batch, and premise batch\n",
        "\n",
        "# training data\n",
        "train_conclusions_stances = []\n",
        "for i in range(len(train_conclusions)):\n",
        "  train_conclusions_stances.append(train_conclusions[i] + train_stances[i])\n",
        "\n",
        "# validation data\n",
        "val_conclusions_stances = []\n",
        "for i in range(len(val_conclusions)):\n",
        "  val_conclusions_stances.append(val_conclusions[i] + val_stances[i])\n",
        "\n",
        "# full data\n",
        "full_conclusions_stances = []\n",
        "for i in range(len(full_conclusions)):\n",
        "  full_conclusions_stances.append(full_conclusions[i] + full_stances[i])"
      ],
      "metadata": {
        "id": "A-J8F0f84SOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define batch size\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "SAHqMaOF3QiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define functions to chunk data for batches\n",
        "\n",
        "# for train labels\n",
        "def chunk(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i: i+n]\n",
        "\n",
        "# for train features\n",
        "def chunk_multi(lst1, lst2, n):\n",
        "    for i in range(0, len(lst1), n):\n",
        "        yield lst1[i: i+n], lst2[i: i+n]"
      ],
      "metadata": {
        "id": "HPVATQvA3QfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function to batch input data \n",
        "# tokenize and encode simultaneously since we are using HuggingFace\n",
        "\n",
        "# batch\n",
        "train_input_batches = [b for b in chunk_multi(train_conclusions_stances, train_premises, batch_size)]\n",
        "val_size = 1\n",
        "full_size = 1\n",
        "val_input_batches = [b for b in chunk_multi(val_conclusions_stances, val_premises, val_size)]\n",
        "full_input_batches = [b for b in chunk_multi(full_conclusions_stances, full_premises, full_size)]\n",
        "\n",
        "# tokenize + encode\n",
        "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]\n",
        "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n",
        "full_input_batches = [tokenizer(*batch) for batch in full_input_batches]\n"
      ],
      "metadata": {
        "id": "qW7pLX6r3XN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check training data example\n",
        "print(train_input_batches[0])\n",
        "encoded_tst = tokenizer.hf_tokenizer.batch_decode(train_input_batches[0]['input_ids'])\n",
        "encoded_tst[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ueZWWuXw8REg",
        "outputId": "30bcda07-76ab-47c3-ca91-0daf4b3465fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  2188, 29477,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] homeopathy brings more harm than good [SEP] against [SEP] homeopathy uses natural remedies that have little to no side affects on the body. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check validation data example\n",
        "print(val_input_batches[0])\n",
        "encoded_tst2 = tokenizer.hf_tokenizer.batch_decode(val_input_batches[0]['input_ids'])\n",
        "encoded_tst2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "cob9vDK-6n3N",
        "outputId": "e259c95c-afca-444f-e836-4503a58daab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1996, 19076,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2591,  2865,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0],\n",
            "        [  101,  2057,  2323,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] the vow of celibacy should be abandoned [SEP] against [SEP] the vow of celibacy should be promoted as it brings the sense of self control and purity to a person's soul. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to batch class labels\n",
        "# a single observation's label is a list of 20 labels\n",
        "\n",
        "def encode_labels(labels: List[List[int]]) -> torch.FloatTensor:\n",
        "    \"\"\"Turns the batch of labels into a tensor\n",
        "\n",
        "    Args:\n",
        "        labels (List[List[int]]): List of all lists of labels in batch\n",
        "\n",
        "    Returns:\n",
        "        torch.FloatTensor: Tensor of all lists of labels in batch\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.LongTensor(labels)\n"
      ],
      "metadata": {
        "id": "hmjoSi9t3bDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply function to batch labels in same order as inputs\n",
        "# batch\n",
        "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
        "val_label_batches = [b for b in chunk(val_labels, val_size)]\n",
        "full_label_batches = [b for b in chunk(full_labels, full_size)]\n",
        "# tokenize + encode\n",
        "train_label_batches = [encode_labels(batch) for batch in train_label_batches]\n",
        "val_label_batches = [encode_labels(batch) for batch in val_label_batches]\n",
        "full_label_batches = [encode_labels(batch) for batch in full_label_batches]"
      ],
      "metadata": {
        "id": "qJKaO7Wm3fIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMDqYTjL9HES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}